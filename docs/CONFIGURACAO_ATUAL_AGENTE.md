# ðŸ”§ ConfiguraÃ§Ã£o Atual do Agente - DocumentaÃ§Ã£o TÃ©cnica Completa

## ðŸ“‹ InformaÃ§Ãµes Gerais

**Data de CriaÃ§Ã£o**: 13 de Agosto de 2025  
**VersÃ£o**: 2.0-simplificada-restaurada  
**Status**: âœ… **SISTEMA TOTALMENTE OPERACIONAL**  
**Ãšltima AtualizaÃ§Ã£o**: RestauraÃ§Ã£o completa do sistema  

## ðŸ—ï¸ Arquitetura do Sistema Restaurado

### **Diagrama de Alto NÃ­vel**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Interface     â”‚    â”‚    Orquestrador      â”‚    â”‚   Agente         â”‚
â”‚   do UsuÃ¡rio    â”‚â”€â”€â”€â–¶â”‚    Simplificado      â”‚â”€â”€â”€â–¶â”‚   Pesquisador    â”‚
â”‚  (simple_main)  â”‚    â”‚ (simple_orchestrator)â”‚    â”‚ (research_agent) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚                           â”‚
                                â–¼                           â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚   GlossÃ¡rio     â”‚         â”‚      LLM        â”‚
                       â”‚   TÃ©cnico       â”‚         â”‚  (Gemini 2.5)   â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚                           â”‚
                                â–¼                           â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚   Pinecone      â”‚         â”‚   Resposta      â”‚
                       â”‚ (Host Personalizado)      â”‚   Formatada     â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ðŸ”‘ ConfiguraÃ§Ãµes de Chaves e APIs

### **1. Google Gemini API**
```bash
# Arquivo: .env
GEMINI_API_KEY=your_gemini_api_key_here
GOOGLE_API_KEY=your_gemini_api_key_here
```

**ConfiguraÃ§Ãµes do LLM**:
- **Modelo**: `gemini-2.5-flash`
- **Provider**: Google
- **Temperature**: 0.1 (determinÃ­stico)
- **Max Tokens**: 6000
- **API Endpoint**: AutomÃ¡tico via SDK

### **2. Pinecone Vector Database**
```bash
# Arquivo: .env
PINECONE_API_KEY=your_pinecone_api_key_here
PINECONE_INDEX=agentes-juridicos
PINECONE_ENVIRONMENT=us-east-1
```

**ConfiguraÃ§Ã£o Especial**:
- **Host Personalizado**: `agentes-juridicos-10b89ab.svc.aped-4627-b74a.pinecone.io`
- **Ãndice**: `agentes-juridicos`
- **Ambiente**: `us-east-1` (configurado mas nÃ£o usado)
- **Total de Vetores**: 6.967
- **DimensÃµes**: 768

## ðŸ” Sistema de Retrieval do Pinecone

### **1. ImplementaÃ§Ã£o Atual**
O sistema usa uma **implementaÃ§Ã£o personalizada** que contorna o SDK padrÃ£o do Pinecone devido a problemas de DNS.

### **2. Arquivo Principal**
```python
# src/tools/pinecone_search_tool.py
class PineconeSearchTool:
    def __init__(self):
        # Host personalizado que funciona
        self.custom_host = "agentes-juridicos-10b89ab.svc.aped-4627-b74a.pinecone.io"
        self.api_key = pinecone_api_key
```

### **3. Processo de Retrieval**
```python
def _query_pinecone_custom(self, vector: List[float], top_k: int = 5):
    # URL para query no host personalizado
    query_url = f"https://{self.custom_host}/query"
    
    # Headers necessÃ¡rios
    headers = {
        'Api-Key': self.api_key,
        'Content-Type': 'application/json'
    }
    
    # Payload da query
    payload = {
        'vector': vector,
        'topK': top_k,
        'includeMetadata': True
    }
    
    # Executa query via HTTP POST
    response = requests.post(query_url, headers=headers, json=payload, timeout=30)
```

### **4. Embedding Model**
```python
# ConfiguraÃ§Ãµes do embedding
self.config = {
    'embedding_model': 'models/text-embedding-004',
    'top_k': 15,
    'similarity_threshold': 0.3,
    'final_result_count': 10,
    'task_type': 'retrieval_query'
}
```

### **5. Fluxo de Retrieval Completo**
```
1. Input Query â†’ Texto da consulta
2. Embedding Generation â†’ text-embedding-004 (768 dimensÃµes)
3. HTTP POST â†’ Host personalizado do Pinecone
4. Vector Search â†’ Busca por similaridade
5. Results Filtering â†’ Threshold 0.3+
6. Metadata Extraction â†’ Metadados dos documentos
7. Response Formatting â†’ Formato padronizado
```

## ðŸ§  ConfiguraÃ§Ã£o do LLM (Gemini 2.5)

### **1. InicializaÃ§Ã£o**
```python
# src/agents/research_agent.py
def _create_llm_instance(self):
    import google.generativeai as genai
    
    api_key = self.llm_config.get('api_key') or os.getenv('GEMINI_API_KEY')
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel(self.llm_config.get('model', 'gemini-2.5-flash'))
    return model
```

### **2. ConfiguraÃ§Ãµes de Prompt**
```python
# Prompt para sÃ­ntese especÃ­fica e objetiva
synthesis_prompt = f"""
VocÃª Ã© um especialista jurÃ­dico. Com base nos documentos fornecidos, responda de forma OBJETIVA Ã  pergunta:

"{query}"

DOCUMENTOS DISPONÃVEIS:
{context_text}

INSTRUÃ‡Ã•ES OBRIGATÃ“RIAS:
1. Responda de forma NATURAL e DIRETA, como um especialista jurÃ­dico
2. Extraia informaÃ§Ãµes ESPECÃFICAS dos documentos
3. Cite as fontes usando o TÃTULO real da nota tÃ©cnica
4. Use linguagem clara e profissional, sem expressÃµes informais
5. Organize as informaÃ§Ãµes de forma lÃ³gica e prÃ¡tica
6. NÃ£o use [DOCUMENTO X] - use sempre as referÃªncias reais
7. NÃ£o use expressÃµes como "colega", "amigo", "prezado" - seja direto e objetivo
"""
```

## ðŸ”„ Fluxo de Processamento Completo

### **1. InicializaÃ§Ã£o do Sistema**
```python
# simple_main.py
def configurar_llms():
    default_config = {
        'provider': 'gemini',
        'model': 'gemini-2.5-flash',
        'api_key': os.getenv('GEMINI_API_KEY'),
        'temperature': 0.1,
        'max_tokens': 4000
    }
    
    llm_configs = {
        'default': default_config,
        'research': {
            **default_config,
            'temperature': 0.1,
            'max_tokens': 6000
        }
    }
```

### **2. OrquestraÃ§Ã£o**
```python
# src/agents/simple_orchestrator.py
class SimpleLegalOrchestrator:
    def __init__(self, llm_configs, output_dir=None):
        self._initialize_research_agent()
        self.glossary = GlossaryIntegration()
        self.metrics = {'total_queries': 0, 'research_queries': 0}
```

### **3. Processamento da Query**
```python
async def process_query(self, query: str):
    # 1. Cria contexto
    context = AgentContext(session_id=workflow_id, ...)
    
    # 2. Processa com glossÃ¡rio
    processed_query = self.glossary.processar_query_completa(query)
    
    # 3. Executa pesquisa
    result = await self._execute_research(query, context)
    
    # 4. Formata resposta
    formatted_result = self._format_research_response(result, query)
    
    # 5. Salva em TXT
    txt_file_path = self._save_response_to_txt(formatted_result, workflow_id, "research")
```

## ðŸ“ Estrutura de Arquivos Atual

### **Arquivos Principais**
```
â”œâ”€â”€ simple_main.py                          # Interface principal
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ base_agent.py                  # Classe base
â”‚   â”‚   â”œâ”€â”€ research_agent.py              # Agente pesquisador
â”‚   â”‚   â””â”€â”€ simple_orchestrator.py         # Orquestrador
â”‚   â”œâ”€â”€ tools/
â”‚   â”‚   â””â”€â”€ pinecone_search_tool.py        # Ferramenta Pinecone (personalizada)
â”‚   â”œâ”€â”€ glossary/
â”‚   â”‚   â””â”€â”€ technical_glossary.py          # GlossÃ¡rio tÃ©cnico
â”‚   â”œâ”€â”€ integration/
â”‚   â”‚   â””â”€â”€ glossary_integration.py        # IntegraÃ§Ã£o do glossÃ¡rio
â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”‚   â””â”€â”€ query_preprocessor.py          # PrÃ©-processamento
â”‚   â””â”€â”€ postprocessing/
â”‚       â””â”€â”€ query_postprocessor.py         # PÃ³s-processamento
```

### **Arquivos de ConfiguraÃ§Ã£o**
```
â”œâ”€â”€ .env                                    # VariÃ¡veis de ambiente
â”œâ”€â”€ requirements.txt                        # DependÃªncias Python
â””â”€â”€ pyproject.toml                         # ConfiguraÃ§Ã£o do projeto
```

## ðŸ“Š MÃ©tricas e Performance

### **1. Performance Atual**
- **Tempo de Embedding**: 0.3-1.3 segundos
- **Tempo de Busca**: 0.6 segundos
- **Tempo Total**: 12-15 segundos
- **Taxa de Sucesso**: 100%

### **2. Capacidades do Sistema**
- **Base de Conhecimento**: 6.967 documentos
- **DimensÃµes dos Vetores**: 768
- **Threshold de Similaridade**: 0.3+
- **Resultados por Busca**: 5-15 documentos
- **Scores TÃ­picos**: 60-80%

## ðŸš¨ Pontos CrÃ­ticos da ConfiguraÃ§Ã£o

### **1. Host Personalizado do Pinecone**
- **CRÃTICO**: O sistema depende do host `agentes-juridicos-10b89ab.svc.aped-4627-b74a.pinecone.io`
- **Motivo**: Problemas de DNS com hosts padrÃ£o do Pinecone
- **SoluÃ§Ã£o Implementada**: Bypass do SDK via HTTP direto

### **2. ConfiguraÃ§Ã£o do Embedding**
- **Modelo**: `text-embedding-004` (Google)
- **DimensÃµes**: 768 (fixo)
- **Task Type**: `retrieval_query`

### **3. ConfiguraÃ§Ã£o do LLM**
- **Modelo**: `gemini-2.5-flash`
- **Temperature**: 0.1 (determinÃ­stico)
- **Max Tokens**: 6000

## ðŸ”§ DependÃªncias e VersÃµes

### **1. Python**
- **VersÃ£o**: 3.10.13
- **Arquitetura**: x86_64 (macOS)

### **2. Pacotes Principais**
```bash
google-generativeai>=0.3.0    # Gemini API
pinecone-client>=2.2.4        # Pinecone SDK (nÃ£o usado atualmente)
python-dotenv>=1.0.0          # VariÃ¡veis de ambiente
requests                       # HTTP requests (para Pinecone personalizado)
numpy                          # Processamento numÃ©rico
```

### **3. Estrutura de DiretÃ³rios**
```
agente-pesquisa-juridica-v2.0/
â”œâ”€â”€ .venv/                    # Ambiente virtual
â”œâ”€â”€ src/                      # CÃ³digo fonte
â”œâ”€â”€ docs/                     # DocumentaÃ§Ã£o
â”œâ”€â”€ respostas/                # Respostas geradas
â”œâ”€â”€ origem/                   # Documentos originais
â””â”€â”€ testes/                   # Testes do sistema
```

## âœ… Status de Funcionamento

### **1. Componentes Operacionais**
- âœ… **Interface Principal** (`simple_main.py`)
- âœ… **Orquestrador** (`simple_orchestrator.py`)
- âœ… **Agente Pesquisador** (`research_agent.py`)
- âœ… **Ferramenta Pinecone** (versÃ£o personalizada)
- âœ… **LLM Gemini** (2.5 Flash)
- âœ… **GlossÃ¡rio TÃ©cnico**
- âœ… **Sistema de Arquivos TXT**

### **2. Funcionalidades Testadas**
- âœ… **ConexÃ£o Pinecone** (host personalizado)
- âœ… **GeraÃ§Ã£o de Embeddings** (text-embedding-004)
- âœ… **Busca Vetorial** (similaridade)
- âœ… **SÃ­ntese com LLM** (Gemini 2.5)
- âœ… **FormataÃ§Ã£o de Respostas**
- âœ… **Salvamento em TXT**
- âœ… **MÃ©tricas do Sistema**

## ðŸŽ¯ Resumo da ConfiguraÃ§Ã£o

O sistema estÃ¡ configurado com uma **arquitetura simplificada e robusta** que:

1. **Usa host personalizado** do Pinecone para contornar problemas de DNS
2. **Implementa retrieval direto** via HTTP para mÃ¡xima confiabilidade
3. **Utiliza Gemini 2.5 Flash** para sÃ­ntese de alta qualidade
4. **MantÃ©m simplicidade** com apenas 3 componentes principais
5. **Preserva funcionalidade completa** de pesquisa jurÃ­dica

**Status**: âœ… **SISTEMA TOTALMENTE OPERACIONAL E DOCUMENTADO**

---

**Ãšltima AtualizaÃ§Ã£o**: 13 de Agosto de 2025  
**ResponsÃ¡vel**: RestauraÃ§Ã£o do sistema  
**VersÃ£o**: 2.0-simplificada-restaurada
